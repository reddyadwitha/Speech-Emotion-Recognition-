{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2f5a103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import glob\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from tqdm import tqdm\n",
    "import plotly.offline as py\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "py.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35c41036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                path  source  actor gender  \\\n",
      "0  C:\\Users\\adwit\\Downloads\\audio_speech_actors_0...       1      1   male   \n",
      "1  C:\\Users\\adwit\\Downloads\\audio_speech_actors_0...       1      1   male   \n",
      "2  C:\\Users\\adwit\\Downloads\\audio_speech_actors_0...       1      1   male   \n",
      "3  C:\\Users\\adwit\\Downloads\\audio_speech_actors_0...       1      1   male   \n",
      "4  C:\\Users\\adwit\\Downloads\\audio_speech_actors_0...       1      1   male   \n",
      "\n",
      "   intensity  statement  repetition  emotion label  \n",
      "0          0          0           0        1     1  \n",
      "1          0          0           1        1     1  \n",
      "2          0          1           0        1     1  \n",
      "3          0          1           1        1     1  \n",
      "4          0          0           0        2     2  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def metadata(basepath):\n",
    "    df = pd.DataFrame(columns=['path', 'source', 'actor', 'gender', 'intensity', 'statement', 'repetition', 'emotion'])\n",
    "    count = 0\n",
    "\n",
    "    for sub_dir in os.listdir(basepath):\n",
    "        sub_dir_path = os.path.join(basepath, sub_dir)\n",
    "\n",
    "        if os.path.isdir(sub_dir_path):\n",
    "            for f in os.listdir(sub_dir_path):\n",
    "                filename = f.split('.')[0].split('-')\n",
    "                if len(filename) == 7:\n",
    "                    path = os.path.join(sub_dir_path, f)\n",
    "                    src = int(filename[1])\n",
    "                    actor = int(filename[-1].split()[0]) \n",
    "                    emotion = int(filename[2])\n",
    "                    gender = \"female\" if int(actor) % 2 == 0 else \"male\"\n",
    "                    intensity = 0 if filename[3] == '01' else 1\n",
    "                    statement = 0 if filename[4] == '01' else 1\n",
    "                    repeat = 0 if filename[5] == '01' else 1\n",
    "\n",
    "                    df.loc[count] = [path, src, actor, gender, intensity, statement, repeat, emotion]\n",
    "                    count += 1\n",
    "\n",
    "    labels = []\n",
    "    for i in range(len(df)):\n",
    "        if df.emotion[i] == 1:\n",
    "            label = \"1\"\n",
    "        elif df.emotion[i] == 2:\n",
    "            label = \"2\"\n",
    "        elif df.emotion[i] == 3:\n",
    "            label = \"3\"\n",
    "        elif df.emotion[i] == 4:\n",
    "            label = \"4\"\n",
    "        elif df.emotion[i] == 5:\n",
    "            label = \"5\"\n",
    "        elif df.emotion[i] == 6:\n",
    "            label = \"6\"\n",
    "        elif df.emotion[i] == 7:\n",
    "            label = \"7\"\n",
    "        elif df.emotion[i] == 8:\n",
    "            label = \"8\"\n",
    "        else:\n",
    "            label = \"_none\"\n",
    "\n",
    "        labels.append(label)\n",
    "\n",
    "    df['label'] = labels\n",
    "    return df\n",
    "\n",
    "basepath = r\"C:\\Users\\adwit\\Downloads\\audio_speech_actors_01-24\"\n",
    "df = metadata(basepath)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9880f2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_augment(spec: np.ndarray, num_mask=1,\n",
    "                 freq_masking_max_percentage=0.10, time_masking_max_percentage=0.15):\n",
    "\n",
    "    spec = spec.copy()\n",
    "    for i in range(num_mask):\n",
    "        all_frames_num, all_freqs_num = spec.shape\n",
    "        freq_percentage = random.uniform(0, freq_masking_max_percentage)\n",
    "\n",
    "        num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "        f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "        f0 = int(f0)\n",
    "        spec[:, f0:f0 + num_freqs_to_mask] = 0.000\n",
    "\n",
    "        time_percentage = random.uniform(0.0, time_masking_max_percentage)\n",
    "\n",
    "        num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "        t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "        t0 = int(t0)\n",
    "        spec[t0:t0 + num_frames_to_mask, :] = 0.000\n",
    "\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e54bc8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1440/1440 [38:33<00:00,  1.61s/it]\n"
     ]
    }
   ],
   "source": [
    "class AugmentedSpectrograms():\n",
    "    def __init__(self, df, outputpath, mel=True, mfcc=False, spectral=False, mfccbanks=20, n_mels=128):\n",
    "        self.df = df\n",
    "        self.mel = mel\n",
    "        self.mfcc = mfcc\n",
    "        self.spectral = spectral\n",
    "        self.mfccbanks = mfccbanks\n",
    "        self.n_mels = n_mels\n",
    "        self.outputpath = outputpath\n",
    "\n",
    "    def get_augmented_spectrograms(self):\n",
    "        for index, row in tqdm(self.df.iterrows(), total=self.df.shape[0]):\n",
    "            emotion = row['label']\n",
    "            path = os.path.join(self.outputpath, emotion)\n",
    "\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "\n",
    "            x, sample_rate = librosa.load(row['path'])\n",
    "            original_filename = f'{emotion}_{index + 1}'\n",
    "            self.generate_augmented_spectrogram(x, sample_rate, path, original_filename)\n",
    "            self.generate_augmented_spectrogram(x, sample_rate, path, original_filename)\n",
    "\n",
    "    def generate_augmented_spectrogram(self, x, sample_rate, path, original_filename):\n",
    "        if self.mel:\n",
    "            mel_features = librosa.feature.melspectrogram(y=x, sr=sample_rate, n_mels=self.n_mels)\n",
    "            log_mel_features = librosa.power_to_db(mel_features, ref=np.max)\n",
    "\n",
    "            for i in range(2):  # Generate 2 augmented samples\n",
    "                augmented_spec = spec_augment(log_mel_features)\n",
    "                self.save_spectrogram(augmented_spec, sample_rate, path, original_filename)\n",
    "\n",
    "    def save_spectrogram(self, features, sample_rate, path, original_filename):\n",
    "        fig = plt.figure(figsize=(12, 4))\n",
    "        ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "        ax.set_axis_off()\n",
    "        fig.add_axes(ax)\n",
    "        librosa.display.specshow(features, sr=sample_rate, x_axis='time', y_axis='mel')\n",
    "\n",
    "        save_path = os.path.join(path, f'{original_filename}.jpg')\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "\n",
    "outputpath = r\"C:\\Users\\adwit\\Downloads\\specti-newaug\"  \n",
    "augmented_spectrogram_generator = AugmentedSpectrograms(df, outputpath=outputpath, mel=True, mfcc=False, spectral=False)\n",
    "augmented_spectrogram_generator.get_augmented_spectrograms()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba6f2e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def load_chromagram(chromagram_path):\n",
    "    chromagram = Image.open(chromagram_path)\n",
    "    return chromagram\n",
    "\n",
    "def save_chromagram(chromagram, chromagram_path):\n",
    "    chromagram.save(chromagram_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d29bcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1: 100%|███████████████████████████████████████████████████████████████████████████████| 96/96 [00:15<00:00,  6.03it/s]\n",
      "2: 100%|█████████████████████████████████████████████████████████████████████████████| 192/192 [00:32<00:00,  5.91it/s]\n",
      "3: 100%|█████████████████████████████████████████████████████████████████████████████| 192/192 [00:32<00:00,  5.90it/s]\n",
      "4: 100%|█████████████████████████████████████████████████████████████████████████████| 192/192 [00:35<00:00,  5.39it/s]\n",
      "5: 100%|█████████████████████████████████████████████████████████████████████████████| 192/192 [00:38<00:00,  5.02it/s]\n",
      "6: 100%|█████████████████████████████████████████████████████████████████████████████| 192/192 [00:34<00:00,  5.55it/s]\n",
      "7: 100%|█████████████████████████████████████████████████████████████████████████████| 192/192 [00:35<00:00,  5.35it/s]\n",
      "8: 100%|█████████████████████████████████████████████████████████████████████████████| 192/192 [00:34<00:12,  5.19it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ChromagramAugmentation():\n",
    "    def __init__(self, chromagram_dir, noise_mean=0, noise_std=0.005):\n",
    "        self.chromagram_dir = chromagram_dir\n",
    "        self.noise_mean = noise_mean\n",
    "        self.noise_std = noise_std\n",
    "\n",
    "    def augment_with_noise(self):\n",
    "        target_total_samples = 4320\n",
    "        original_samples = 1440\n",
    "        augmented_samples_needed = target_total_samples - original_samples\n",
    "        current_total_samples = 0\n",
    "\n",
    "        for emotion_dir in os.listdir(self.chromagram_dir):\n",
    "            emotion_path = os.path.join(self.chromagram_dir, emotion_dir)\n",
    "            if os.path.isdir(emotion_path):\n",
    "                chromagram_files = [f for f in os.listdir(emotion_path) if f.endswith('.jpg')]\n",
    "                num_original_chromagrams = len(chromagram_files)\n",
    "\n",
    "                for idx, chromagram_file in tqdm(enumerate(chromagram_files), total=num_original_chromagrams, desc=emotion_dir):\n",
    "                    chromagram_path = os.path.join(emotion_path, chromagram_file)\n",
    "                    chromagram = load_chromagram(chromagram_path)\n",
    "\n",
    "                    num_augmentations = min(2, int(np.ceil(augmented_samples_needed / num_original_chromagrams)))\n",
    "\n",
    "                    for i in range(num_augmentations):\n",
    "                        augmented_chromagram = self.add_noise_to_chromagram(chromagram)\n",
    "                        new_index = original_samples + current_total_samples + i + 1\n",
    "                        augmented_chromagram_filename = f\"{emotion_dir}_{new_index}.jpg\"\n",
    "                        augmented_chromagram_path = os.path.join(emotion_path, augmented_chromagram_filename)\n",
    "                        save_chromagram(augmented_chromagram, augmented_chromagram_path)\n",
    "\n",
    "                    current_total_samples += num_augmentations\n",
    "                    if current_total_samples >= augmented_samples_needed:\n",
    "                        break\n",
    "\n",
    "                if current_total_samples >= augmented_samples_needed:\n",
    "                    break\n",
    "\n",
    "    def add_noise_to_chromagram(self, chromagram):\n",
    "        width, height = chromagram.size\n",
    "        noise = np.random.normal(self.noise_mean, self.noise_std, (height, width, 3))\n",
    "        noisy_chromagram_array = np.array(chromagram) + noise\n",
    "        noisy_chromagram_array = np.clip(noisy_chromagram_array, 0, 255).astype(np.uint8)\n",
    "        return Image.fromarray(noisy_chromagram_array)\n",
    "\n",
    "# Example usage\n",
    "chromagram_dir = r\"C:\\Users\\adwit\\Downloads\\chroma-augm\"\n",
    "augmenter = ChromagramAugmentation(chromagram_dir)\n",
    "augmenter.augment_with_noise()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a15e261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\adwit\\anaconda3\\anaconda33\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\adwit\\anaconda3\\anaconda33\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "118/118 [==============================] - 66s 536ms/step - loss: 1.7072 - accuracy: 0.4245 - val_loss: 5.7624 - val_accuracy: 0.1905\n",
      "Epoch 2/100\n",
      "118/118 [==============================] - 72s 611ms/step - loss: 0.7420 - accuracy: 0.7344 - val_loss: 1.0195 - val_accuracy: 0.6167\n",
      "Epoch 3/100\n",
      "118/118 [==============================] - 103s 873ms/step - loss: 0.3522 - accuracy: 0.8816 - val_loss: 0.7217 - val_accuracy: 0.7595\n",
      "Epoch 4/100\n",
      "118/118 [==============================] - 115s 978ms/step - loss: 0.1437 - accuracy: 0.9576 - val_loss: 0.6481 - val_accuracy: 0.7905\n",
      "Epoch 5/100\n",
      "118/118 [==============================] - 108s 918ms/step - loss: 0.0891 - accuracy: 0.9746 - val_loss: 0.2887 - val_accuracy: 0.8976\n",
      "Epoch 6/100\n",
      "118/118 [==============================] - 109s 922ms/step - loss: 0.0525 - accuracy: 0.9883 - val_loss: 0.2323 - val_accuracy: 0.9095\n",
      "Epoch 7/100\n",
      "118/118 [==============================] - 108s 917ms/step - loss: 0.1847 - accuracy: 0.9399 - val_loss: 2.0293 - val_accuracy: 0.5667\n",
      "Epoch 8/100\n",
      "118/118 [==============================] - 126s 1s/step - loss: 0.1246 - accuracy: 0.9621 - val_loss: 0.5565 - val_accuracy: 0.8095\n",
      "Epoch 9/100\n",
      "118/118 [==============================] - 112s 952ms/step - loss: 0.0509 - accuracy: 0.9854 - val_loss: 23.9717 - val_accuracy: 0.5738\n",
      "Epoch 10/100\n",
      "118/118 [==============================] - 112s 949ms/step - loss: 0.0381 - accuracy: 0.9881 - val_loss: 0.1025 - val_accuracy: 0.9714\n",
      "Epoch 11/100\n",
      "118/118 [==============================] - 122s 1s/step - loss: 0.0220 - accuracy: 0.9939 - val_loss: 0.2588 - val_accuracy: 0.9071\n",
      "Epoch 12/100\n",
      "118/118 [==============================] - 114s 965ms/step - loss: 0.0213 - accuracy: 0.9944 - val_loss: 0.1135 - val_accuracy: 0.9667\n",
      "Epoch 13/100\n",
      "118/118 [==============================] - 105s 891ms/step - loss: 0.0144 - accuracy: 0.9960 - val_loss: 0.4769 - val_accuracy: 0.8333\n",
      "Epoch 14/100\n",
      "118/118 [==============================] - 103s 877ms/step - loss: 0.0123 - accuracy: 0.9971 - val_loss: 0.0434 - val_accuracy: 0.9857\n",
      "Epoch 15/100\n",
      "118/118 [==============================] - 105s 889ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0753 - val_accuracy: 0.9667\n",
      "Epoch 16/100\n",
      "118/118 [==============================] - 118s 999ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 4.0461 - val_accuracy: 0.4524\n",
      "Epoch 17/100\n",
      "118/118 [==============================] - 110s 930ms/step - loss: 0.0350 - accuracy: 0.9876 - val_loss: 0.9187 - val_accuracy: 0.8429\n",
      "Epoch 18/100\n",
      "118/118 [==============================] - 110s 930ms/step - loss: 0.0448 - accuracy: 0.9870 - val_loss: 0.4548 - val_accuracy: 0.8857\n",
      "Epoch 19/100\n",
      "118/118 [==============================] - 109s 926ms/step - loss: 0.0613 - accuracy: 0.9801 - val_loss: 0.6251 - val_accuracy: 0.8429\n",
      "Epoch 20/100\n",
      "118/118 [==============================] - 124s 1s/step - loss: 0.0613 - accuracy: 0.9804 - val_loss: 1.0564 - val_accuracy: 0.7286\n",
      "Epoch 21/100\n",
      "118/118 [==============================] - 103s 874ms/step - loss: 0.0785 - accuracy: 0.9746 - val_loss: 0.5227 - val_accuracy: 0.8429\n",
      "Epoch 22/100\n",
      "118/118 [==============================] - 100s 844ms/step - loss: 0.0367 - accuracy: 0.9891 - val_loss: 0.2868 - val_accuracy: 0.9262\n",
      "Epoch 23/100\n",
      "118/118 [==============================] - 102s 863ms/step - loss: 0.0165 - accuracy: 0.9966 - val_loss: 5.1498 - val_accuracy: 0.9000\n",
      "Epoch 24/100\n",
      "118/118 [==============================] - 96s 816ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.1424 - val_accuracy: 0.9643\n",
      "Epoch 25/100\n",
      "118/118 [==============================] - 95s 805ms/step - loss: 0.0213 - accuracy: 0.9944 - val_loss: 0.3181 - val_accuracy: 0.9167\n",
      "Epoch 26/100\n",
      "118/118 [==============================] - 96s 813ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.0256 - val_accuracy: 0.9905\n",
      "Epoch 27/100\n",
      "118/118 [==============================] - 94s 796ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0671 - val_accuracy: 0.9905\n",
      "Epoch 28/100\n",
      "118/118 [==============================] - 94s 798ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0477 - val_accuracy: 0.9857\n",
      "Epoch 29/100\n",
      "118/118 [==============================] - 94s 798ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0807 - val_accuracy: 0.9786\n",
      "Epoch 30/100\n",
      "118/118 [==============================] - 94s 798ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.1184 - val_accuracy: 0.9857\n",
      "Epoch 31/100\n",
      "118/118 [==============================] - 94s 793ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.0913 - val_accuracy: 0.9667\n",
      "Epoch 32/100\n",
      "118/118 [==============================] - 94s 798ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0486 - val_accuracy: 0.9857\n",
      "Epoch 33/100\n",
      "118/118 [==============================] - 95s 810ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0857 - val_accuracy: 0.9714\n",
      "Epoch 34/100\n",
      "118/118 [==============================] - 93s 791ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 0.0439 - val_accuracy: 0.9929\n",
      "Epoch 35/100\n",
      "118/118 [==============================] - 94s 800ms/step - loss: 0.0870 - accuracy: 0.9740 - val_loss: 37.2248 - val_accuracy: 0.2905\n",
      "Epoch 36/100\n",
      "118/118 [==============================] - 94s 798ms/step - loss: 0.2098 - accuracy: 0.9370 - val_loss: 3.2546 - val_accuracy: 0.5286\n",
      "Epoch 37/100\n",
      "118/118 [==============================] - 93s 789ms/step - loss: 0.0740 - accuracy: 0.9738 - val_loss: 0.5899 - val_accuracy: 0.8524\n",
      "Epoch 38/100\n",
      "118/118 [==============================] - 93s 789ms/step - loss: 0.0258 - accuracy: 0.9921 - val_loss: 0.4310 - val_accuracy: 0.8714\n",
      "Epoch 39/100\n",
      "118/118 [==============================] - 94s 798ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.0646 - val_accuracy: 0.9786\n",
      "Epoch 40/100\n",
      "118/118 [==============================] - 93s 792ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.1250 - val_accuracy: 0.9833\n",
      "Epoch 41/100\n",
      "118/118 [==============================] - 93s 789ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 0.0742 - val_accuracy: 0.9762\n",
      "Epoch 42/100\n",
      "118/118 [==============================] - 94s 798ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.1307 - val_accuracy: 0.9833\n",
      "Epoch 43/100\n",
      "118/118 [==============================] - 94s 799ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0361 - val_accuracy: 0.9857\n",
      "Epoch 44/100\n",
      "118/118 [==============================] - 92s 782ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.0270 - val_accuracy: 0.9881\n",
      "Epoch 45/100\n",
      "118/118 [==============================] - 94s 797ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.0549 - val_accuracy: 0.9929\n",
      "Epoch 46/100\n",
      "118/118 [==============================] - 93s 790ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.2248 - val_accuracy: 0.9810\n",
      "Epoch 47/100\n",
      "118/118 [==============================] - 93s 789ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.2509 - val_accuracy: 0.9833\n",
      "Epoch 48/100\n",
      "118/118 [==============================] - 94s 798ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 0.9929\n",
      "Epoch 49/100\n",
      "118/118 [==============================] - 92s 781ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.1961 - val_accuracy: 0.9952\n",
      "Epoch 50/100\n",
      "118/118 [==============================] - 93s 785ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.2118 - val_accuracy: 0.9905\n",
      "Epoch 51/100\n",
      "118/118 [==============================] - 93s 787ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.3397 - val_accuracy: 0.9833\n",
      "Epoch 52/100\n",
      "118/118 [==============================] - 93s 793ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.7048 - val_accuracy: 0.9381\n",
      "Epoch 53/100\n",
      "118/118 [==============================] - 93s 787ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 0.2468 - val_accuracy: 0.9357\n",
      "Epoch 54/100\n",
      "118/118 [==============================] - 93s 788ms/step - loss: 0.0288 - accuracy: 0.9910 - val_loss: 0.1412 - val_accuracy: 0.9595\n",
      "Epoch 55/100\n",
      "118/118 [==============================] - 93s 789ms/step - loss: 0.0659 - accuracy: 0.9775 - val_loss: 0.8042 - val_accuracy: 0.8286\n",
      "Epoch 56/100\n",
      "118/118 [==============================] - 93s 790ms/step - loss: 0.1341 - accuracy: 0.9595 - val_loss: 0.8370 - val_accuracy: 0.8095\n",
      "Epoch 57/100\n",
      "118/118 [==============================] - 94s 797ms/step - loss: 0.0506 - accuracy: 0.9846 - val_loss: 0.2794 - val_accuracy: 0.9143\n",
      "Epoch 58/100\n",
      "118/118 [==============================] - 95s 805ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 0.1521 - val_accuracy: 0.9500\n",
      "Epoch 59/100\n",
      "118/118 [==============================] - 94s 801ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.0699 - val_accuracy: 0.9786\n",
      "Epoch 60/100\n",
      "118/118 [==============================] - 94s 793ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 0.0244 - val_accuracy: 0.9905\n",
      "Epoch 61/100\n",
      "118/118 [==============================] - 96s 812ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.0457 - val_accuracy: 0.9833\n",
      "Epoch 62/100\n",
      "118/118 [==============================] - 97s 822ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.1927 - val_accuracy: 0.9357\n",
      "Epoch 63/100\n",
      "118/118 [==============================] - 93s 791ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.1293 - val_accuracy: 0.9667\n",
      "Epoch 64/100\n",
      "118/118 [==============================] - 102s 863ms/step - loss: 0.0066 - accuracy: 0.9971 - val_loss: 0.2152 - val_accuracy: 0.9690\n",
      "Epoch 65/100\n",
      "118/118 [==============================] - 105s 892ms/step - loss: 0.0071 - accuracy: 0.9971 - val_loss: 0.0863 - val_accuracy: 0.9714\n",
      "Epoch 66/100\n",
      "118/118 [==============================] - 113s 955ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.0322 - val_accuracy: 0.9857\n",
      "Epoch 67/100\n",
      "118/118 [==============================] - 109s 924ms/step - loss: 0.0080 - accuracy: 0.9971 - val_loss: 0.0357 - val_accuracy: 0.9905\n",
      "Epoch 68/100\n",
      "118/118 [==============================] - 102s 866ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0651 - val_accuracy: 0.9857\n",
      "Epoch 69/100\n",
      "118/118 [==============================] - 107s 905ms/step - loss: 0.0048 - accuracy: 0.9981 - val_loss: 0.1943 - val_accuracy: 0.9762\n",
      "Epoch 70/100\n",
      "118/118 [==============================] - 105s 889ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0222 - val_accuracy: 0.9881\n",
      "Epoch 71/100\n",
      "118/118 [==============================] - 109s 921ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.3444 - val_accuracy: 0.9619\n",
      "Epoch 72/100\n",
      "118/118 [==============================] - 103s 875ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0139 - val_accuracy: 0.9929\n",
      "Epoch 73/100\n",
      "118/118 [==============================] - 104s 882ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.0308 - val_accuracy: 0.9881\n",
      "Epoch 74/100\n",
      "118/118 [==============================] - 107s 905ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0600 - val_accuracy: 0.9762\n",
      "Epoch 75/100\n",
      "118/118 [==============================] - 103s 876ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.2176 - val_accuracy: 0.9643\n",
      "Epoch 76/100\n",
      "118/118 [==============================] - 103s 869ms/step - loss: 0.0274 - accuracy: 0.9910 - val_loss: 0.1663 - val_accuracy: 0.9405\n",
      "Epoch 77/100\n",
      "118/118 [==============================] - 107s 910ms/step - loss: 0.0425 - accuracy: 0.9878 - val_loss: 0.1917 - val_accuracy: 0.9548\n",
      "Epoch 78/100\n",
      "118/118 [==============================] - 107s 903ms/step - loss: 0.0189 - accuracy: 0.9928 - val_loss: 0.1294 - val_accuracy: 0.9667\n",
      "Epoch 79/100\n",
      "118/118 [==============================] - 106s 898ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.0414 - val_accuracy: 0.9881\n",
      "Epoch 80/100\n",
      "118/118 [==============================] - 103s 877ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.0965 - val_accuracy: 0.9786\n",
      "Epoch 81/100\n",
      "118/118 [==============================] - 97s 822ms/step - loss: 0.0183 - accuracy: 0.9939 - val_loss: 0.0932 - val_accuracy: 0.9714\n",
      "Epoch 82/100\n",
      "118/118 [==============================] - 98s 828ms/step - loss: 0.0065 - accuracy: 0.9971 - val_loss: 0.1427 - val_accuracy: 0.9929\n",
      "Epoch 83/100\n",
      "118/118 [==============================] - 107s 905ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.2956 - val_accuracy: 0.9905\n",
      "Epoch 84/100\n",
      "118/118 [==============================] - 103s 868ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.4971 - val_accuracy: 0.9833\n",
      "Epoch 85/100\n",
      "118/118 [==============================] - 100s 850ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.3843 - val_accuracy: 0.9595\n",
      "Epoch 86/100\n",
      "118/118 [==============================] - 103s 872ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.6124 - val_accuracy: 0.9500\n",
      "Epoch 87/100\n",
      "118/118 [==============================] - 100s 846ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.0323 - val_accuracy: 0.9857\n",
      "Epoch 88/100\n",
      "118/118 [==============================] - 105s 890ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.2450 - val_accuracy: 0.9881\n",
      "Epoch 89/100\n",
      "118/118 [==============================] - 98s 831ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.1179 - val_accuracy: 0.9690\n",
      "Epoch 90/100\n",
      "118/118 [==============================] - 104s 879ms/step - loss: 0.0110 - accuracy: 0.9958 - val_loss: 0.4302 - val_accuracy: 0.9357\n",
      "Epoch 91/100\n",
      "118/118 [==============================] - 103s 878ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.3562 - val_accuracy: 0.9595\n",
      "Epoch 92/100\n",
      "118/118 [==============================] - 103s 872ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.1320 - val_accuracy: 0.9762\n",
      "Epoch 93/100\n",
      "118/118 [==============================] - 104s 879ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.0279 - val_accuracy: 0.9881\n",
      "Epoch 94/100\n",
      "118/118 [==============================] - 112s 947ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.1389 - val_accuracy: 0.9667\n",
      "Epoch 95/100\n",
      "118/118 [==============================] - 107s 905ms/step - loss: 0.0182 - accuracy: 0.9936 - val_loss: 5.4239 - val_accuracy: 0.8143\n",
      "Epoch 96/100\n",
      "118/118 [==============================] - 115s 975ms/step - loss: 0.0264 - accuracy: 0.9899 - val_loss: 3.6391 - val_accuracy: 0.5214\n",
      "Epoch 97/100\n",
      "118/118 [==============================] - 110s 936ms/step - loss: 0.0336 - accuracy: 0.9897 - val_loss: 0.0958 - val_accuracy: 0.9667\n",
      "Epoch 98/100\n",
      "118/118 [==============================] - 107s 909ms/step - loss: 0.0308 - accuracy: 0.9902 - val_loss: 0.0720 - val_accuracy: 0.9786\n",
      "Epoch 99/100\n",
      "118/118 [==============================] - 110s 931ms/step - loss: 0.0171 - accuracy: 0.9955 - val_loss: 0.0828 - val_accuracy: 0.9738\n",
      "Epoch 100/100\n",
      "118/118 [==============================] - 101s 856ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.0579 - val_accuracy: 0.9905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d1a73c3a10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit([X_train_s, X_train_s], y_train_s, batch_size=32, epochs=100, validation_data=([X_test_s, X_test_s], y_test_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d40a6b",
   "metadata": {},
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import glob\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from tqdm import tqdm\n",
    "import plotly.offline as py\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "py.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8ebe96",
   "metadata": {},
   "source": [
    "one augmented sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "923ff8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1440/1440 [14:00<00:00,  1.71it/s]\n"
     ]
    }
   ],
   "source": [
    "class AugmentedSpectrograms():\n",
    "    def __init__(self, df, outputpath, mel=True, mfcc=False, spectral=False, mfccbanks=20, n_mels=128):\n",
    "        self.df = df\n",
    "        self.mel = mel\n",
    "        self.mfcc = mfcc\n",
    "        self.spectral = spectral\n",
    "        self.mfccbanks = mfccbanks\n",
    "        self.n_mels = n_mels\n",
    "        self.outputpath = outputpath\n",
    "\n",
    "    def get_augmented_spectrograms(self):\n",
    "        for index, row in tqdm(self.df.iterrows(), total=self.df.shape[0]):\n",
    "            emotion = row['label']\n",
    "            path = os.path.join(self.outputpath, emotion)\n",
    "\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "\n",
    "            x, sample_rate = librosa.load(row['path'])\n",
    "            original_filename = f'{emotion}_{index + 1}'\n",
    "            self.generate_augmented_spectrogram(x, sample_rate, path, original_filename)\n",
    "\n",
    "    def generate_augmented_spectrogram(self, x, sample_rate, path, original_filename):\n",
    "        if self.mel:\n",
    "            mel_features = librosa.feature.melspectrogram(y=x, sr=sample_rate, n_mels=self.n_mels)\n",
    "            log_mel_features = librosa.power_to_db(mel_features, ref=np.max)\n",
    "\n",
    "            # Apply SpecAugment to the mel spectrogram\n",
    "            augmented_spec = spec_augment(log_mel_features)\n",
    "\n",
    "            # Save the augmented mel spectrogram\n",
    "            self.save_spectrogram(augmented_spec, sample_rate, path, original_filename)\n",
    "\n",
    "    def save_spectrogram(self, features, sample_rate, path, original_filename):\n",
    "        fig = plt.figure(figsize=(12, 4))\n",
    "        ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "        ax.set_axis_off()\n",
    "        fig.add_axes(ax)\n",
    "        librosa.display.specshow(features, sr=sample_rate, x_axis='time', y_axis='mel')\n",
    "\n",
    "        save_path = os.path.join(path, f'{original_filename}.jpg')\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "\n",
    "# Example usage for generating augmented spectrograms\n",
    "outputpath = r\"C:\\Users\\adwit\\Downloads\\new_spectograms\"  # Change this to the desired output path\n",
    "augmented_spectrogram_generator = AugmentedSpectrograms(df, outputpath=outputpath, mel=True, mfcc=False, spectral=False)\n",
    "\n",
    "# Generate augmented spectrograms\n",
    "augmented_spectrogram_generator.get_augmented_spectrograms()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09701831",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 96/96 [00:06<00:00, 13.99it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 192/192 [00:20<00:00,  9.43it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 192/192 [00:20<00:00,  9.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 192/192 [00:16<00:00, 11.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 192/192 [00:15<00:00, 12.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 192/192 [00:15<00:00, 12.78it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 192/192 [00:14<00:00, 12.82it/s]\n"
     ]
    }
   ],
   "source": [
    "class AugmentedSpectrograms():\n",
    "    def __init__(self, df, outputpath, mel=True, mfcc=False, spectral=False, mfccbanks=20, n_mels=128):\n",
    "        self.df = df\n",
    "        self.mel = mel\n",
    "        self.mfcc = mfcc\n",
    "        self.spectral = spectral\n",
    "        self.mfccbanks = mfccbanks\n",
    "        self.n_mels = n_mels\n",
    "        self.outputpath = outputpath\n",
    "\n",
    "    def get_augmented_spectrograms(self):\n",
    "        classes = self.df['label'].unique()  # Get all unique classes\n",
    "        for emotion in classes:\n",
    "            class_df = self.df[self.df['label'] == emotion]\n",
    "            path = os.path.join(self.outputpath, emotion)\n",
    "\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "\n",
    "            for index, row in tqdm(class_df.iterrows(), total=class_df.shape[0]):\n",
    "                x, sample_rate = librosa.load(row['path'])\n",
    "                original_filename = f'{emotion}_{index + 1}'\n",
    "                self.generate_augmented_spectrogram(x, sample_rate, path, original_filename)\n",
    "\n",
    "    def generate_augmented_spectrogram(self, x, sample_rate, path, original_filename):\n",
    "        if self.mel:\n",
    "            mel_features = librosa.feature.melspectrogram(y=x, sr=sample_rate, n_mels=self.n_mels)\n",
    "            log_mel_features = librosa.power_to_db(mel_features, ref=np.max)\n",
    "\n",
    "            # Apply SpecAugment to the mel spectrogram\n",
    "            augmented_spec = spec_augment(log_mel_features)\n",
    "\n",
    "            # Save the augmented mel spectrogram\n",
    "            self.save_spectrogram(augmented_spec, sample_rate, path, original_filename)\n",
    "\n",
    "    def save_spectrogram(self, features, sample_rate, path, original_filename):\n",
    "        fig = plt.figure(figsize=(12, 4))\n",
    "        ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "        ax.set_axis_off()\n",
    "        fig.add_axes(ax)\n",
    "        librosa.display.specshow(features, sr=sample_rate, x_axis='time', y_axis='mel')\n",
    "\n",
    "        save_path = os.path.join(path, f'{original_filename}.jpg')\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "\n",
    "# Example usage for generating augmented spectrograms\n",
    "outputpath = r\"C:\\Users\\adwit\\Downloads\\new_spectograms\"  # Change this to the desired output path\n",
    "augmented_spectrogram_generator = AugmentedSpectrograms(df, outputpath=outputpath, mel=True, mfcc=False, spectral=False)\n",
    "\n",
    "# Generate augmented spectrograms\n",
    "augmented_spectrogram_generator.get_augmented_spectrograms()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acfcd8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1440/1440 [08:51<00:00,  2.71it/s]\n"
     ]
    }
   ],
   "source": [
    "class AugmentedSpectrograms():\n",
    "    def __init__(self, df, outputpath, mel=True, mfcc=False, spectral=False, mfccbanks=20, n_mels=128):\n",
    "        self.df = df\n",
    "        self.mel = mel\n",
    "        self.mfcc = mfcc\n",
    "        self.spectral = spectral\n",
    "        self.mfccbanks = mfccbanks\n",
    "        self.n_mels = n_mels\n",
    "        self.outputpath = outputpath\n",
    "\n",
    "    def get_augmented_spectrograms(self):\n",
    "        for index, row in tqdm(self.df.iterrows(), total=self.df.shape[0]):\n",
    "            emotion = row['label']\n",
    "            path = os.path.join(self.outputpath, emotion)\n",
    "\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "\n",
    "            x, sample_rate = librosa.load(row['path'])\n",
    "            original_filename = f'{emotion}_{index + 1}'\n",
    "            self.generate_augmented_spectrogram(x, sample_rate, path, original_filename)\n",
    "            self.generate_augmented_spectrogram(x, sample_rate, path, original_filename)\n",
    "\n",
    "    def generate_augmented_spectrogram(self, x, sample_rate, path, original_filename):\n",
    "        if self.mel:\n",
    "            mel_features = librosa.feature.melspectrogram(y=x, sr=sample_rate, n_mels=self.n_mels)\n",
    "            log_mel_features = librosa.power_to_db(mel_features, ref=np.max)\n",
    "\n",
    "            # Apply SpecAugment to the mel spectrogram\n",
    "            for _ in range(2):  # Generate 2 augmented samples\n",
    "                augmented_spec = spec_augment(log_mel_features)\n",
    "\n",
    "                # Save the augmented mel spectrogram\n",
    "                self.save_spectrogram(augmented_spec, sample_rate, path, original_filename)\n",
    "\n",
    "    def save_spectrogram(self, features, sample_rate, path, original_filename):\n",
    "        fig = plt.figure(figsize=(12, 4))\n",
    "        ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "        ax.set_axis_off()\n",
    "        fig.add_axes(ax)\n",
    "        librosa.display.specshow(features, sr=sample_rate, x_axis='time', y_axis='mel')\n",
    "\n",
    "        save_path = os.path.join(path, f'{original_filename}.jpg')\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "\n",
    "# Example usage for generating augmented spectrograms\n",
    "outputpath = r\"C:\\Users\\adwit\\Downloads\\specti-new\"  # Change this to the desired output path\n",
    "augmented_spectrogram_generator = AugmentedSpectrograms(df, outputpath=outputpath, mel=True, mfcc=False, spectral=False)\n",
    "\n",
    "# Generate augmented spectrograms\n",
    "augmented_spectrogram_generator.get_augmented_spectrograms()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75e8b81",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ChromagramAugmentation():\n",
    "    def __init__(self, chromagram_dir, noise_mean=0, noise_std=0.005):\n",
    "        self.chromagram_dir = chromagram_dir\n",
    "        self.noise_mean = noise_mean\n",
    "        self.noise_std = noise_std\n",
    "\n",
    "    def augment_with_noise(self):\n",
    "        num_original_chromagrams = 1450  # Update this with your actual number of original chromagrams\n",
    "        desired_total_chromagrams = 4196\n",
    "        num_augmentations_needed = desired_total_chromagrams - num_original_chromagrams\n",
    "\n",
    "        for emotion_dir in os.listdir(self.chromagram_dir):\n",
    "            emotion_path = os.path.join(self.chromagram_dir, emotion_dir)\n",
    "            if os.path.isdir(emotion_path):\n",
    "                chromagram_files = [f for f in os.listdir(emotion_path) if f.endswith('.jpg')]\n",
    "\n",
    "                for idx, chromagram_file in tqdm(enumerate(chromagram_files), total=num_original_chromagrams, desc=emotion_dir):\n",
    "                    chromagram_path = os.path.join(emotion_path, chromagram_file)\n",
    "                    chromagram = load_chromagram(chromagram_path)\n",
    "\n",
    "                    # Calculate how many times to augment this chromagram\n",
    "                    num_augmentations = int(np.ceil(num_augmentations_needed / num_original_chromagrams))\n",
    "\n",
    "                    # Augment the chromagram\n",
    "                    for i in range(num_augmentations):\n",
    "                        augmented_chromagram = self.add_noise_to_chromagram(chromagram)\n",
    "\n",
    "                        # Determine the new index for augmented chromagrams\n",
    "                        new_index = num_original_chromagrams + idx * num_augmentations + i + 1\n",
    "\n",
    "                        # Save the augmented chromagram\n",
    "                        augmented_chromagram_filename = f\"{emotion_dir}_{new_index}.jpg\"\n",
    "                        augmented_chromagram_path = os.path.join(emotion_path, augmented_chromagram_filename)\n",
    "                        save_chromagram(augmented_chromagram, augmented_chromagram_path)\n",
    "\n",
    "                        num_augmentations_needed -= 1\n",
    "                        if num_augmentations_needed == 0:\n",
    "                            break\n",
    "\n",
    "                    if num_augmentations_needed == 0:\n",
    "                        break\n",
    "\n",
    "    def add_noise_to_chromagram(self, chromagram):\n",
    "        width, height = chromagram.size\n",
    "        noise = np.random.normal(self.noise_mean, self.noise_std, (height, width, 3))\n",
    "        noisy_chromagram_array = np.array(chromagram) + noise\n",
    "        noisy_chromagram_array = np.clip(noisy_chromagram_array, 0, 255).astype(np.uint8)\n",
    "        return Image.fromarray(noisy_chromagram_array)\n",
    "\n",
    "chromagram_dir = r\"C:\\Users\\adwit\\Downloads\\chromagrams\"\n",
    "augmenter = ChromagramAugmentation(chromagram_dir)\n",
    "augmenter.augment_with_noise()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70d372d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def spec_augment(spec: np.ndarray, num_mask=1,\n",
    "                 freq_masking_max_percentage=0.10, time_masking_max_percentage=0.15):\n",
    "\n",
    "    spec = spec.copy()\n",
    "    for i in range(num_mask):\n",
    "        all_frames_num, all_freqs_num = spec.shape\n",
    "        freq_percentage = random.uniform(0, freq_masking_max_percentage)\n",
    "\n",
    "        num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "        f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "        f0 = int(f0)\n",
    "        spec[:, f0:f0 + num_freqs_to_mask] = 0.000\n",
    "\n",
    "        time_percentage = random.uniform(0.0, time_masking_max_percentage)\n",
    "\n",
    "        num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "        t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "        t0 = int(t0)\n",
    "        spec[t0:t0 + num_frames_to_mask, :] = 0.000\n",
    "\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae7900f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "dataset_dir = r\"C:\\Users\\adwit\\Downloads\\specti-newaug\"\n",
    "\n",
    "spectrograms = []\n",
    "labels = []\n",
    "for emotion_category in os.listdir(dataset_dir):\n",
    "    category_dir = os.path.join(dataset_dir, emotion_category)\n",
    "    if os.path.isdir(category_dir):\n",
    "        for filename in os.listdir(category_dir):\n",
    "            img = load_img(os.path.join(category_dir, filename), target_size=(256,256,3))\n",
    "            img_array = img_to_array(img)\n",
    "            spectrograms.append(img_array)\n",
    "            labels.append(emotion_category)\n",
    "spectrograms = np.array(spectrograms)\n",
    "labels = np.array(labels)\n",
    "\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(spectrograms, labels, test_size=0.1, random_state=42)\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train_s = label_binarizer.fit_transform(y_train_s)\n",
    "y_test_s = label_binarizer.transform(y_test_s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349e3102",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Input, BatchNormalization, Dropout\n",
    "input_shape = (256,256, 3)\n",
    "#sequential model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "x = model(input_layer)\n",
    "\n",
    "concatenated_input = Concatenate()([x, x])\n",
    "num_classes = 8\n",
    "output_layer = Dense(num_classes, activation='softmax')(concatenated_input)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cf0bf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "model_top.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_top.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236d833",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train_s, y_train_s, epochs=100, batch_size=32, validation_data=(X_test_s, y_test_s))\n",
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "# Assuming you have trained your CNN model and it's stored in a variable called 'model'\n",
    "\n",
    "# Extract loss values from history\n",
    "import matplotlib.pyplot as plt\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Plot loss vs. epochs\n",
    "plt.plot(range(1, len(train_loss) + 1), train_loss, label='Training Loss')\n",
    "plt.plot(range(1, len(val_loss) + 1), val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs. Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming you have trained your CNN model and obtained predictions\n",
    "# Replace these lines with your actual prediction code\n",
    "# model = ... (your CNN model)\n",
    "y_pred = model.predict(X_test_s)  # Example of getting predictions, adjust according to your model\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(np.argmax(y_test_s, axis=1), np.argmax(y_pred_s, axis=1))\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision = precision_score(np.argmax(y_test_s, axis=1), np.argmax(y_pred, axis=1), average='weighted')\n",
    "recall = recall_score(np.argmax(y_test_s, axis=1), np.argmax(y_pred, axis=1), average='weighted')\n",
    "f1 = f1_score(np.argmax(y_test_s, axis=1), np.argmax(y_pred, axis=1), average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Average Precision:\", precision)\n",
    "print(\"Average Recall:\", recall)\n",
    "print(\"Average F1-score:\", f1)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract accuracy values from history\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Plot accuracy vs. epochs\n",
    "plt.plot(range(1, len(train_accuracy) + 1), train_accuracy, label='Train')\n",
    "plt.plot(range(1, len(val_accuracy) + 1), val_accuracy, label='Test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b572c92",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model_top.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c1a4be",
   "metadata": {},
   "source": [
    "Chromagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c0ea05",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def metadata(basepath):\n",
    "    df = pd.DataFrame(columns=['path', 'source', 'actor', 'gender', 'intensity', 'statement', 'repetition', 'emotion'])\n",
    "    count = 0\n",
    "\n",
    "    for sub_dir in os.listdir(basepath):\n",
    "        sub_dir_path = os.path.join(basepath, sub_dir)\n",
    "\n",
    "        if os.path.isdir(sub_dir_path):\n",
    "            for f in os.listdir(sub_dir_path):\n",
    "                filename = f.split('.')[0].split('-')\n",
    "                if len(filename) == 7:\n",
    "                    path = os.path.join(sub_dir_path, f)\n",
    "                    src = int(filename[1])\n",
    "                    actor = int(filename[-1].split()[0])  # Extract actor removing extra characters\n",
    "                    emotion = int(filename[2])\n",
    "                    gender = \"female\" if int(actor) % 2 == 0 else \"male\"\n",
    "                    intensity = 0 if filename[3] == '01' else 1\n",
    "                    statement = 0 if filename[4] == '01' else 1\n",
    "                    repeat = 0 if filename[5] == '01' else 1\n",
    "\n",
    "                    df.loc[count] = [path, src, actor, gender, intensity, statement, repeat, emotion]\n",
    "                    count += 1\n",
    "\n",
    "    labels = []\n",
    "    for i in range(len(df)):\n",
    "        if df.emotion[i] == 1:\n",
    "            label = \"1\"\n",
    "        elif df.emotion[i] == 2:\n",
    "            label = \"2\"\n",
    "        elif df.emotion[i] == 3:\n",
    "            label = \"3\"\n",
    "        elif df.emotion[i] == 4:\n",
    "            label = \"4\"\n",
    "        elif df.emotion[i] == 5:\n",
    "            label = \"5\"\n",
    "        elif df.emotion[i] == 6:\n",
    "            label = \"6\"\n",
    "        elif df.emotion[i] == 7:\n",
    "            label = \"7\"\n",
    "        elif df.emotion[i] == 8:\n",
    "            label = \"8\"\n",
    "        else:\n",
    "            label = \"_none\"\n",
    "\n",
    "        labels.append(label)\n",
    "\n",
    "    df['label'] = labels\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "basepath = r\"C:\\Users\\adwit\\Downloads\\audio_speech_actors_01-24\"\n",
    "df = metadata(basepath)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0412a3a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "class Spectrograms():\n",
    "    def __init__(self, df, outputpath, sample=False, augmentation=False, mel=False, mfcc=False, spectral=False, chroma=False, mfccbanks=20, n_mels=128):\n",
    "        self.df = df\n",
    "        self.augmentation = augmentation\n",
    "        self.mel = mel\n",
    "        self.mfcc = mfcc\n",
    "        self.spectral = spectral\n",
    "        self.chroma = chroma\n",
    "        self.mfccbanks = mfccbanks\n",
    "        self.n_mels = n_mels\n",
    "        self.outputpath = outputpath\n",
    "        self.sample = sample\n",
    "\n",
    "    def get_spectrograms(self):\n",
    "        if self.sample:\n",
    "            x, sample_rate = librosa.load(self.df['path'].iloc[0])\n",
    "            self.generate(x, sample_rate, '', 0, self.df['label'].iloc[0])\n",
    "\n",
    "        else:\n",
    "            for index, row in tqdm(self.df.iterrows(), total=self.df.shape[0]):\n",
    "                emotion = row['label']\n",
    "                path = os.path.join(self.outputpath, emotion)\n",
    "\n",
    "                if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "\n",
    "                x, sample_rate = librosa.load(row['path'])\n",
    "                self.generate(x, sample_rate, path, index, emotion)\n",
    "\n",
    "    def generate(self, x, sample_rate, path, count, emotion):\n",
    "        if self.mel:\n",
    "            mel_features = librosa.feature.melspectrogram(y=x, sr=sample_rate, n_mels=self.n_mels)\n",
    "            log_mel_features = librosa.power_to_db(mel_features, ref=np.max)\n",
    "            fig = plt.figure(figsize=(12, 4))\n",
    "            ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "            ax.set_axis_off()\n",
    "            fig.add_axes(ax)\n",
    "            librosa.display.specshow(log_mel_features, sr=sample_rate, x_axis='time', y_axis='mel')\n",
    "            if self.sample:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.savefig(os.path.join(path, f'{emotion}_{count}.jpg'))\n",
    "                plt.close()\n",
    "\n",
    "        if self.mfcc:\n",
    "            mfcc_features = librosa.feature.mfcc(x, sr=sample_rate, n_mfcc=self.mfccbanks)\n",
    "            fig = plt.figure(figsize=(12, 4))\n",
    "            ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "            ax.set_axis_off()\n",
    "            fig.add_axes(ax)\n",
    "            librosa.display.specshow(mfcc_features, sr=sample_rate, x_axis='time', y_axis='mel')\n",
    "            if self.sample:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.savefig(os.path.join(path, f'{emotion}_{count}_mfcc.jpg'))\n",
    "                plt.close()\n",
    "\n",
    "        if self.spectral:\n",
    "            spectral_features = librosa.feature.spectral_contrast(x, sr=sample_rate)\n",
    "            fig = plt.figure(figsize=(12, 4))\n",
    "            ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "            ax.set_axis_off()\n",
    "            fig.add_axes(ax)\n",
    "            librosa.display.specshow(spectral_features, sr=sample_rate, x_axis='time', y_axis='mel')\n",
    "            if self.sample:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.savefig(os.path.join(path, f'{emotion}_{count}_spectral.jpg'))\n",
    "                plt.close()\n",
    "\n",
    "        if self.chroma:\n",
    "            chroma_features = librosa.feature.chroma_stft(y=x, sr=sample_rate)\n",
    "            fig = plt.figure(figsize=(12, 4))\n",
    "            ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "            ax.set_axis_off()\n",
    "            fig.add_axes(ax)\n",
    "            librosa.display.specshow(chroma_features, sr=sample_rate, x_axis='time', y_axis='chroma')\n",
    "            if self.sample:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.savefig(os.path.join(path, f'{emotion}_{count}.jpg'))\n",
    "                plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a438f589",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "spectrogram_generator = Spectrograms(df, outputpath=r\"C:\\Users\\adwit\\Downloads\\spectogramsnewest\", sample=False,mel=True)\n",
    "spectrogram_generator.get_spectrograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c654a869",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_images(directory):\n",
    "    total_images = 0\n",
    "    subdirectories = []\n",
    "\n",
    "    # Iterate over all items in the directory\n",
    "    for item in os.listdir(directory):\n",
    "        item_path = os.path.join(directory, item)\n",
    "\n",
    "        # If it's a file and has an image extension, count it\n",
    "        if os.path.isfile(item_path) and item.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "            total_images += 1\n",
    "        # If it's a directory, add it to the subdirectories list\n",
    "        elif os.path.isdir(item_path):\n",
    "            subdirectories.append(item)\n",
    "\n",
    "    # Recursively count images in subdirectories\n",
    "    for subdir in subdirectories:\n",
    "        subdir_path = os.path.join(directory, subdir)\n",
    "        total_images += count_images(subdir_path)\n",
    "\n",
    "    return total_images\n",
    "\n",
    "def count_shape_of_directory(directory):\n",
    "    subdirectories = []\n",
    "    total_images = 0\n",
    "\n",
    "    # Iterate over all items in the directory\n",
    "    for item in os.listdir(directory):\n",
    "        item_path = os.path.join(directory, item)\n",
    "\n",
    "        # If it's a directory, add it to the subdirectories list\n",
    "        if os.path.isdir(item_path):\n",
    "            subdirectories.append(item)\n",
    "        elif os.path.isfile(item_path) and item.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "            total_images += 1\n",
    "    for subdir in subdirectories:\n",
    "        subdir_path = os.path.join(directory, subdir)\n",
    "        total_images += count_images(subdir_path)\n",
    "\n",
    "    return len(subdirectories), total_images\n",
    "directory_path = r\"C:\\Users\\adwit\\Downloads\\spectogramsnewest\"\n",
    "num_subdirectories, total_images = count_shape_of_directory(directory_path)\n",
    "print(f\"Number of subdirectories: {num_subdirectories}\")\n",
    "print(f\"Total number of images: {total_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558d25d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def spec_augment(spec: np.ndarray, num_mask=1,\n",
    "                 freq_masking_max_percentage=0.10, time_masking_max_percentage=0.15):\n",
    "\n",
    "    spec = spec.copy()\n",
    "    for i in range(num_mask):\n",
    "        all_frames_num, all_freqs_num = spec.shape\n",
    "        freq_percentage = random.uniform(0, freq_masking_max_percentage)\n",
    "\n",
    "        num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "        f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "        f0 = int(f0)\n",
    "        spec[:, f0:f0 + num_freqs_to_mask] = 0.000\n",
    "\n",
    "        time_percentage = random.uniform(0.0, time_masking_max_percentage)\n",
    "\n",
    "        num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "        t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "        t0 = int(t0)\n",
    "        spec[t0:t0 + num_frames_to_mask, :] = 0.000\n",
    "\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4936ee45",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fde38b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_images(directory):\n",
    "    total_images = 0\n",
    "    subdirectories = []\n",
    "    for item in os.listdir(directory):\n",
    "        item_path = os.path.join(directory, item)\n",
    "        if os.path.isfile(item_path) and item.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "            total_images += 1\n",
    "        elif os.path.isdir(item_path):\n",
    "            subdirectories.append(item)\n",
    "    for subdir in subdirectories:\n",
    "        subdir_path = os.path.join(directory, subdir)\n",
    "        total_images += count_images(subdir_path)\n",
    "\n",
    "    return total_images\n",
    "\n",
    "def count_shape_of_directory(directory):\n",
    "    subdirectories = []\n",
    "    total_images = 0\n",
    "    for item in os.listdir(directory):\n",
    "        item_path = os.path.join(directory, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            subdirectories.append(item)\n",
    "        elif os.path.isfile(item_path) and item.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "            total_images += 1\n",
    "    for subdir in subdirectories:\n",
    "        subdir_path = os.path.join(directory, subdir)\n",
    "        total_images += count_images(subdir_path)\n",
    "\n",
    "    return len(subdirectories), total_images\n",
    "directory_path = r\"C:\\Users\\adwit\\Downloads\\chroma-augm\"\n",
    "num_subdirectories, total_images = count_shape_of_directory(directory_path)\n",
    "print(f\"Number of subdirectories: {num_subdirectories}\")\n",
    "print(f\"Total number of images: {total_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9038338a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "dataset_dir = r\"C:\\Users\\adwit\\Downloads\\chroma-augm\"\n",
    "\n",
    "chromagrams = []\n",
    "labels = []\n",
    "\n",
    "for emotion_category in os.listdir(dataset_dir):\n",
    "    category_dir = os.path.join(dataset_dir, emotion_category)\n",
    "    if os.path.isdir(category_dir):\n",
    "        for filename in os.listdir(category_dir):\n",
    "            img = load_img(os.path.join(category_dir, filename), target_size=(256,256,3))\n",
    "            img_array = img_to_array(img)\n",
    "            chromagrams.append(img_array)\n",
    "            labels.append(emotion_category)\n",
    "\n",
    "chromagrams = np.array(chromagrams)\n",
    "labels = np.array(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(chromagrams, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train = label_binarizer.fit_transform(y_train)\n",
    "y_test = label_binarizer.transform(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86881c95",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Input, BatchNormalization, Dropout\n",
    "input_shape = (256,256, 3)\n",
    "#sequential model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "x = model(input_layer)\n",
    "\n",
    "concatenated_input = Concatenate()([x, x])\n",
    "num_classes = 8\n",
    "output_layer = Dense(num_classes, activation='softmax')(concatenated_input)\n",
    "model_top = Model(inputs=input_layer, outputs=output_layer)\n",
    "model_top.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_top.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef450f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "model_top.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_top.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98224f8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "model_top.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_top.fit(X_train, y_train, batch_size=32, epochs=30, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6697ffa4",
   "metadata": {},
   "source": [
    "Spectograms-100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bb1aed",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "model_top.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_top.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b229eb6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model_top.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa5db46",
   "metadata": {},
   "source": [
    "Concatenating outputs from two different layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4df33e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "dataset_dir = r\"C:\\Users\\adwit\\Downloads\\specti-newaug\"\n",
    "\n",
    "spectrograms = []\n",
    "labels = []\n",
    "for emotion_category in os.listdir(dataset_dir):\n",
    "    category_dir = os.path.join(dataset_dir, emotion_category)\n",
    "    if os.path.isdir(category_dir):\n",
    "        for filename in os.listdir(category_dir):\n",
    "            img = load_img(os.path.join(category_dir, filename), target_size=(150,150,3))\n",
    "            img_array = img_to_array(img)\n",
    "            spectrograms.append(img_array)\n",
    "            labels.append(emotion_category)\n",
    "spectrograms = np.array(spectrograms)\n",
    "labels = np.array(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(spectrograms, labels, test_size=0.1, random_state=42)\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train = label_binarizer.fit_transform(y_train)\n",
    "y_test = label_binarizer.transform(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9e2775",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Input, BatchNormalization, Dropout\n",
    "input_shape = (150, 150, 3)  \n",
    "\n",
    "input_layer1 = Input(shape=input_shape)\n",
    "x1 = Conv2D(32, (3, 3), activation='relu')(input_layer1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "\n",
    "input_layer2 = Input(shape=input_shape)\n",
    "x2 = Conv2D(64, (3, 3), activation='relu')(input_layer2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "\n",
    "concatenated_input = Concatenate()([x1, x2])\n",
    "\n",
    "flatten_layer = Flatten()(concatenated_input)\n",
    "\n",
    "x = Dense(128, activation='relu')(flatten_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output layer\n",
    "num_classes = 8\n",
    "output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=[input_layer1, input_layer2], outputs=output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c374aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit([X_train, X_train], y_train, batch_size=32, epochs=50, validation_data=([X_test, X_test], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae24f2f",
   "metadata": {},
   "source": [
    "Chromagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049ed6e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "dataset_dir = r\"C:\\Users\\adwit\\Downloads\\chroma-augm\"\n",
    "\n",
    "spectrograms = []\n",
    "labels = []\n",
    "for emotion_category in os.listdir(dataset_dir):\n",
    "    category_dir = os.path.join(dataset_dir, emotion_category)\n",
    "    if os.path.isdir(category_dir):\n",
    "        for filename in os.listdir(category_dir):\n",
    "            img = load_img(os.path.join(category_dir, filename), target_size=(150,150,3))\n",
    "            img_array = img_to_array(img)\n",
    "            spectrograms.append(img_array)\n",
    "            labels.append(emotion_category)\n",
    "spectrograms = np.array(spectrograms)\n",
    "labels = np.array(labels)\n",
    "\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(spectrograms, labels, test_size=0.1, random_state=42)\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train_c = label_binarizer.fit_transform(y_train_c)\n",
    "y_test_c = label_binarizer.transform(y_test_c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3832ea17",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Input, BatchNormalization, Dropout\n",
    "input_shape = (150, 150, 3)  \n",
    "\n",
    "input_layer1 = Input(shape=input_shape)\n",
    "x1 = Conv2D(32, (3, 3), activation='relu')(input_layer1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "\n",
    "input_layer2 = Input(shape=input_shape)\n",
    "x2 = Conv2D(64, (3, 3), activation='relu')(input_layer2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "\n",
    "concatenated_input = Concatenate()([x1, x2])\n",
    "\n",
    "flatten_layer = Flatten()(concatenated_input)\n",
    "\n",
    "x = Dense(128, activation='relu')(flatten_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output layer\n",
    "num_classes = 8\n",
    "output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=[input_layer1, input_layer2], outputs=output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08d6142",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit([X_train_c, X_train_c], y_train_c, batch_size=32, epochs=100, validation_data=([X_test_c, X_test_c], y_test_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f3868f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict([X_test_c,X_test_c])\n",
    "\n",
    "# Convert the one-hot encoded labels back to original labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_test_c, axis=1)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_true_labels, y_pred_labels)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true_labels, y_pred_labels))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true_labels, y_pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4797a46c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Input, BatchNormalization, Dropout\n",
    "input_shape = (256,256, 3)  \n",
    "\n",
    "input_layer1 = Input(shape=input_shape)\n",
    "x1 = Conv2D(32, (3, 3), activation='relu')(input_layer1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "\n",
    "input_layer2 = Input(shape=input_shape)\n",
    "x2 = Conv2D(64, (3, 3), activation='relu')(input_layer2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "\n",
    "concatenated_input = Concatenate()([x1, x2])\n",
    "\n",
    "flatten_layer = Flatten()(concatenated_input)\n",
    "\n",
    "x = Dense(128, activation='relu')(flatten_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output layer\n",
    "num_classes = 8\n",
    "output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=[input_layer1, input_layer2], outputs=output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e65fb6d",
   "metadata": {},
   "source": [
    "strides(spectograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ce9358",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "dataset_dir = r\"C:\\Users\\adwit\\Downloads\\specti-newaug\"\n",
    "\n",
    "spectrograms = []\n",
    "labels = []\n",
    "for emotion_category in os.listdir(dataset_dir):\n",
    "    category_dir = os.path.join(dataset_dir, emotion_category)\n",
    "    if os.path.isdir(category_dir):\n",
    "        for filename in os.listdir(category_dir):\n",
    "            img = load_img(os.path.join(category_dir, filename), target_size=(150,150,3))\n",
    "            img_array = img_to_array(img)\n",
    "            spectrograms.append(img_array)\n",
    "            labels.append(emotion_category)\n",
    "spectrograms = np.array(spectrograms)\n",
    "labels = np.array(labels)\n",
    "\n",
    "X_train_s1, X_test_s1, y_train_s1, y_test_s1 = train_test_split(spectrograms, labels, test_size=0.1, random_state=42)\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train_s1 = label_binarizer.fit_transform(y_train_s1)\n",
    "y_test_s1 = label_binarizer.transform(y_test_s1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b767ad19",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Input, BatchNormalization, Dropout\n",
    "\n",
    "input_shape = (150,150, 3)  \n",
    "\n",
    "input_layer1 = Input(shape=input_shape)\n",
    "x1 = Conv2D(32, (3, 3), activation='relu', strides=(2, 2), padding='valid')(input_layer1)  # Stride added here\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = MaxPooling2D(pool_size=(2, 2), strides=(3, 3))(x1)  # Stride added here\n",
    "\n",
    "input_layer2 = Input(shape=input_shape)\n",
    "x2 = Conv2D(64, (3, 3), activation='relu', strides=(2, 2), padding='valid')(input_layer2)  # Stride added here\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = MaxPooling2D(pool_size=(2, 2), strides=(3, 3))(x2)  # Stride added here\n",
    "\n",
    "concatenated_input = Concatenate()([x1, x2])\n",
    "\n",
    "flatten_layer = Flatten()(concatenated_input)\n",
    "\n",
    "x = Dense(128, activation='relu')(flatten_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output layer\n",
    "num_classes = 8\n",
    "output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=[input_layer1, input_layer2], outputs=output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db2a597",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit([X_train_s1, X_train_s1], y_train_s1, batch_size=32, epochs=50, validation_data=([X_test_s1, X_test_s1], y_test_s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d00548b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit([X_train_s1, X_train_s1], y_train_s1, batch_size=32, epochs=100, validation_data=([X_test_s1, X_test_s1], y_test_s1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badd2f99",
   "metadata": {},
   "source": [
    "COMPLEX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d91c0f",
   "metadata": {},
   "source": [
    "SPECTOGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aabe07b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "dataset_dir = r\"C:\\Users\\adwit\\Downloads\\specti-newaug\"\n",
    "\n",
    "spectrograms = []\n",
    "labels = []\n",
    "for emotion_category in os.listdir(dataset_dir):\n",
    "    category_dir = os.path.join(dataset_dir, emotion_category)\n",
    "    if os.path.isdir(category_dir):\n",
    "        for filename in os.listdir(category_dir):\n",
    "            img = load_img(os.path.join(category_dir, filename), target_size=(224,224,3))\n",
    "            img_array = img_to_array(img)\n",
    "            spectrograms.append(img_array)\n",
    "            labels.append(emotion_category)\n",
    "spectrograms = np.array(spectrograms)\n",
    "labels = np.array(labels)\n",
    "\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(spectrograms, labels, test_size=0.1, random_state=42)\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train_s = label_binarizer.fit_transform(y_train_s)\n",
    "y_test_s = label_binarizer.transform(y_test_s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1ff9ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Input, BatchNormalization, Dropout\n",
    "\n",
    "input_shape = (224,224, 3)\n",
    "\n",
    "# First Input and Convolutional Block\n",
    "input_layer1 = Input(shape=input_shape)\n",
    "x1 = Conv2D(32, (3, 3), activation='relu', padding='same', strides=(2, 2))(input_layer1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = MaxPooling2D(pool_size=(3, 3), strides=(3, 3))(x1)\n",
    "\n",
    "# Second Input and Convolutional Block\n",
    "input_layer2 = Input(shape=input_shape)\n",
    "x2 = Conv2D(128, (3, 3), activation='relu', padding='same', strides=(2, 2))(input_layer2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = MaxPooling2D(pool_size=(3, 3), strides=(3, 3))(x2)\n",
    "\n",
    "# Concatenation\n",
    "concatenated_input = Concatenate()([x1, x2])\n",
    "\n",
    "# Third Convolutional Block\n",
    "x3 = Conv2D(256, (3, 3), activation='relu', padding='same')(concatenated_input)\n",
    "x3 = BatchNormalization()(x3)\n",
    "x3 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x3)\n",
    "\n",
    "# Flatten and Dense Layers\n",
    "flatten_layer = Flatten()(x3)\n",
    "x = Dense(128, activation='relu')(flatten_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# Output layer\n",
    "num_classes = 8\n",
    "output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Model definition and compilation\n",
    "model = Model(inputs=[input_layer1, input_layer2], outputs=output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1066ceb",
   "metadata": {},
   "source": [
    "COMBINED-NEWWW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c026aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Input, BatchNormalization, Dropout\n",
    "import numpy as np\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# Define the model architecture\n",
    "input_layer1 = Input(shape=input_shape)\n",
    "x1 = Conv2D(32, (3, 3), activation='relu', padding='same', strides=(2, 2))(input_layer1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = MaxPooling2D(pool_size=(3, 3), strides=(3, 3))(x1)\n",
    "\n",
    "input_layer2 = Input(shape=input_shape)\n",
    "x2 = Conv2D(128, (3, 3), activation='relu', padding='same', strides=(2, 2))(input_layer2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = MaxPooling2D(pool_size=(3, 3), strides=(3, 3))(x2)\n",
    "\n",
    "concatenated_input = Concatenate()([x1, x2])\n",
    "\n",
    "x3 = Conv2D(256, (3, 3), activation='relu', padding='same')(concatenated_input)\n",
    "x3 = BatchNormalization()(x3)\n",
    "x3 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x3)\n",
    "\n",
    "flatten_layer = Flatten()(x3)\n",
    "x = Dense(128, activation='relu')(flatten_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "num_classes = 8\n",
    "output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Original model\n",
    "model = Model(inputs=[input_layer1, input_layer2], outputs=output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# New model to extract features\n",
    "feature_extraction_model = Model(inputs=model.input, outputs=model.layers[-5].output)\n",
    "\n",
    "# Extract features\n",
    "features = feature_extraction_model.predict([spectrograms, spectrograms])\n",
    "\n",
    "# Save features as .npy file\n",
    "np.save(r\"C:\\Users\\adwit\\Downloads\\combined_features\\spectograms_feasnewestdd.npy\", features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a69107",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "dataset_dir = r\"C:\\Users\\adwit\\Downloads\\chroma-augm\"\n",
    "\n",
    "chromagrams = []\n",
    "labels = []\n",
    "\n",
    "for emotion_category in os.listdir(dataset_dir):\n",
    "    category_dir = os.path.join(dataset_dir, emotion_category)\n",
    "    if os.path.isdir(category_dir):\n",
    "        for filename in os.listdir(category_dir):\n",
    "            img = load_img(os.path.join(category_dir, filename), target_size=(224,224,3))\n",
    "            img_array = img_to_array(img)\n",
    "            chromagrams.append(img_array)\n",
    "            labels.append(emotion_category)\n",
    "\n",
    "chromagrams = np.array(chromagrams)\n",
    "labels = np.array(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(chromagrams, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train = label_binarizer.fit_transform(y_train)\n",
    "y_test = label_binarizer.transform(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5296fb1",
   "metadata": {},
   "source": [
    "little new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438d5ba7",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Input, BatchNormalization, Dropout\n",
    "import numpy as np\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# Define the model architecture\n",
    "input_layer1 = Input(shape=input_shape)\n",
    "x1 = Conv2D(32, (3, 3), activation='relu', padding='same', strides=(2, 2))(input_layer1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = MaxPooling2D(pool_size=(3, 3), strides=(3, 3))(x1)\n",
    "\n",
    "input_layer2 = Input(shape=input_shape)\n",
    "x2 = Conv2D(128, (3, 3), activation='relu', padding='same', strides=(2, 2))(input_layer2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = MaxPooling2D(pool_size=(3, 3), strides=(3, 3))(x2)\n",
    "\n",
    "concatenated_input = Concatenate()([x1, x2])\n",
    "\n",
    "x3 = Conv2D(256, (3, 3), activation='relu', padding='same')(concatenated_input)\n",
    "x3 = BatchNormalization()(x3)\n",
    "x3 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x3)\n",
    "\n",
    "# New Convolutional Layer\n",
    "x4 = Conv2D(512, (3, 3), activation='relu', padding='same')(x3)\n",
    "x4 = BatchNormalization()(x4)\n",
    "x4 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x4)\n",
    "\n",
    "flatten_layer = Flatten()(x4)\n",
    "x = Dense(128, activation='relu')(flatten_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "num_classes = 8\n",
    "output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Original model\n",
    "model = Model(inputs=[input_layer1, input_layer2], outputs=output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# New model to extract features\n",
    "feature_extraction_model = Model(inputs=model.input, outputs=x4)\n",
    "\n",
    "# Extract features\n",
    "features = feature_extraction_model.predict([chromagrams, chromagrams])\n",
    "\n",
    "# Save features as .npy file\n",
    "np.save(r\"C:\\Users\\adwit\\Downloads\\combined_features\\chromagrams_feasnewestee.npy\", features)\n",
    "np.save(r\"C:\\Users\\adwit\\Downloads\\combined_features\\chromagrams_labelsnewestee.npy\", labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3884ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Input, BatchNormalization, Dropout\n",
    "import numpy as np\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# Define the model architecture\n",
    "input_layer1 = Input(shape=input_shape)\n",
    "x1 = Conv2D(32, (3, 3), activation='relu', padding='same', strides=(2, 2))(input_layer1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = MaxPooling2D(pool_size=(3, 3), strides=(3, 3))(x1)\n",
    "\n",
    "input_layer2 = Input(shape=input_shape)\n",
    "x2 = Conv2D(128, (3, 3), activation='relu', padding='same', strides=(2, 2))(input_layer2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = MaxPooling2D(pool_size=(3, 3), strides=(3, 3))(x2)\n",
    "\n",
    "concatenated_input = Concatenate()([x1, x2])\n",
    "\n",
    "x3 = Conv2D(256, (3, 3), activation='relu', padding='same')(concatenated_input)\n",
    "x3 = BatchNormalization()(x3)\n",
    "x3 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x3)\n",
    "\n",
    "flatten_layer = Flatten()(x3)\n",
    "x = Dense(128, activation='relu')(flatten_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "num_classes = 8\n",
    "output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Original model\n",
    "model = Model(inputs=[input_layer1, input_layer2], outputs=output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# New model to extract features\n",
    "feature_extraction_model = Model(inputs=model.input, outputs=model.layers[-5].output)\n",
    "\n",
    "# Extract features\n",
    "features = feature_extraction_model.predict([chromagrams, chromagrams])\n",
    "\n",
    "# Save features as .npy file\n",
    "np.save(r\"C:\\Users\\adwit\\Downloads\\combined_features\\chromagrams_feasnewestdd.npy\", features)\n",
    "np.save(r\"C:\\Users\\adwit\\Downloads\\combined_features\\chromagrams_labelsnewestdd.npy\",labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c965b6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "# Load extracted features from spectrograms and chromagrams\n",
    "spectrogram_features = np.load(r\"C:\\Users\\adwit\\Downloads\\combined_features\\spectograms_feasnewestdd.npy\")\n",
    "chromagram_features = np.load(r\"C:\\Users\\adwit\\Downloads\\combined_features\\chromagrams_feasnewestdd.npy\")\n",
    "\n",
    "# Concatenate the features\n",
    "concatenated_features = np.concatenate((spectrogram_features, chromagram_features), axis=1)\n",
    "\n",
    "# Load the labels\n",
    "labels = np.load(r\"C:\\Users\\adwit\\Downloads\\combined_features\\chromagrams_labelsnewestdd.npy\")\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "labels_encoded = label_binarizer.fit_transform(labels)\n",
    "# Split the data into training and testing sets\n",
    "X_train_co, X_test_co, y_train_co, y_test_co = train_test_split(concatenated_features, labels_encoded, test_size=0.1, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def7ef85",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming x_train is your training data\n",
    "print(\"Shape of x_train:\", X_train_co.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a537322d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "\n",
    "# Define and compile the model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(256,)),\n",
    "    BatchNormalization(),  \n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(8, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2bfe16",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_co, y_train_co, epochs=100, batch_size=32, validation_data=(X_test_co, y_test_co))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e55419",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_co, y_train_co, epochs=200, batch_size=32, validation_data=(X_test_co, y_test_co))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e95929",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_co, y_train_co, epochs=300, batch_size=32, validation_data=(X_test_co, y_test_co))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f71265",
   "metadata": {},
   "source": [
    "SPECTOGRAMS-ONE AUGMENTED SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9754c660",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "dataset_dir = r\"C:\\Users\\adwit\\Downloads\\new_spectograms\"\n",
    "\n",
    "spectrograms = []\n",
    "labels = []\n",
    "for emotion_category in os.listdir(dataset_dir):\n",
    "    category_dir = os.path.join(dataset_dir, emotion_category)\n",
    "    if os.path.isdir(category_dir):\n",
    "        for filename in os.listdir(category_dir):\n",
    "            img = load_img(os.path.join(category_dir, filename), target_size=(256,256,3))\n",
    "            img_array = img_to_array(img)\n",
    "            spectrograms.append(img_array)\n",
    "            labels.append(emotion_category)\n",
    "spectrograms = np.array(spectrograms)\n",
    "labels = np.array(labels)\n",
    "\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(spectrograms, labels, test_size=0.1, random_state=42)\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train_s = label_binarizer.fit_transform(y_train_s)\n",
    "y_test_s = label_binarizer.transform(y_test_s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50834b78",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Input, BatchNormalization, Dropout\n",
    "\n",
    "input_shape = (256,256, 3)\n",
    "\n",
    "# First Input and Convolutional Block\n",
    "input_layer1 = Input(shape=input_shape)\n",
    "x1 = Conv2D(32, (3, 3), activation='relu', padding='same', strides=(2, 2))(input_layer1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = MaxPooling2D(pool_size=(3, 3), strides=(3, 3))(x1)\n",
    "\n",
    "# Second Input and Convolutional Block\n",
    "input_layer2 = Input(shape=input_shape)\n",
    "x2 = Conv2D(128, (3, 3), activation='relu', padding='same', strides=(2, 2))(input_layer2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = MaxPooling2D(pool_size=(3, 3), strides=(3, 3))(x2)\n",
    "\n",
    "# Concatenation\n",
    "concatenated_input = Concatenate()([x1, x2])\n",
    "\n",
    "# Third Convolutional Block\n",
    "x3 = Conv2D(256, (3, 3), activation='relu', padding='same')(concatenated_input)\n",
    "x3 = BatchNormalization()(x3)\n",
    "x3 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x3)\n",
    "\n",
    "# Flatten and Dense Layers\n",
    "flatten_layer = Flatten()(x3)\n",
    "x = Dense(128, activation='relu')(flatten_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# Output layer\n",
    "num_classes = 8\n",
    "output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Model definition and compilation\n",
    "model = Model(inputs=[input_layer1, input_layer2], outputs=output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9164faf",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_s, y_train_s, epochs=50, batch_size=32, validation_data=(X_test_s, y_test_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5110b3a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit([X_train_s, X_train_s], y_train_s, batch_size=32, epochs=50, validation_data=([X_test_s, X_test_s], y_test_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35920a36",
   "metadata": {},
   "source": [
    "one augmented sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cc7c2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import glob\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from tqdm import tqdm\n",
    "import plotly.offline as py\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "py.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7392ddd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def metadata(basepath):\n",
    "    df = pd.DataFrame(columns=['path', 'source', 'actor', 'gender', 'intensity', 'statement', 'repetition', 'emotion'])\n",
    "    count = 0\n",
    "\n",
    "    for sub_dir in os.listdir(basepath):\n",
    "        sub_dir_path = os.path.join(basepath, sub_dir)\n",
    "\n",
    "        if os.path.isdir(sub_dir_path):\n",
    "            for f in os.listdir(sub_dir_path):\n",
    "                filename = f.split('.')[0].split('-')\n",
    "                if len(filename) == 7:\n",
    "                    path = os.path.join(sub_dir_path, f)\n",
    "                    src = int(filename[1])\n",
    "                    actor = int(filename[-1].split()[0])  # Extract actor removing extra characters\n",
    "                    emotion = int(filename[2])\n",
    "                    gender = \"female\" if int(actor) % 2 == 0 else \"male\"\n",
    "                    intensity = 0 if filename[3] == '01' else 1\n",
    "                    statement = 0 if filename[4] == '01' else 1\n",
    "                    repeat = 0 if filename[5] == '01' else 1\n",
    "\n",
    "                    df.loc[count] = [path, src, actor, gender, intensity, statement, repeat, emotion]\n",
    "                    count += 1\n",
    "\n",
    "    labels = []\n",
    "    for i in range(len(df)):\n",
    "        if df.emotion[i] == 1:\n",
    "            label = \"1\"\n",
    "        elif df.emotion[i] == 2:\n",
    "            label = \"2\"\n",
    "        elif df.emotion[i] == 3:\n",
    "            label = \"3\"\n",
    "        elif df.emotion[i] == 4:\n",
    "            label = \"4\"\n",
    "        elif df.emotion[i] == 5:\n",
    "            label = \"5\"\n",
    "        elif df.emotion[i] == 6:\n",
    "            label = \"6\"\n",
    "        elif df.emotion[i] == 7:\n",
    "            label = \"7\"\n",
    "        elif df.emotion[i] == 8:\n",
    "            label = \"8\"\n",
    "        else:\n",
    "            label = \"_none\"\n",
    "\n",
    "        labels.append(label)\n",
    "\n",
    "    df['label'] = labels\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "basepath = r\"C:\\Users\\adwit\\Downloads\\audio_speech_actors_01-24\"\n",
    "df = metadata(basepath)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a664ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "class Spectrograms():\n",
    "    def __init__(self, df, outputpath, sample=False, augmentation=False, mel=False, mfcc=False, spectral=False, chroma=False, mfccbanks=20, n_mels=128):\n",
    "        self.df = df\n",
    "        self.augmentation = augmentation\n",
    "        self.mel = mel\n",
    "        self.mfcc = mfcc\n",
    "        self.spectral = spectral\n",
    "        self.chroma = chroma\n",
    "        self.mfccbanks = mfccbanks\n",
    "        self.n_mels = n_mels\n",
    "        self.outputpath = outputpath\n",
    "        self.sample = sample\n",
    "\n",
    "    def get_spectrograms(self):\n",
    "        if self.sample:\n",
    "            x, sample_rate = librosa.load(self.df['path'].iloc[0])\n",
    "            self.generate(x, sample_rate, '', 0, self.df['label'].iloc[0])\n",
    "\n",
    "        else:\n",
    "            for index, row in tqdm(self.df.iterrows(), total=self.df.shape[0]):\n",
    "                emotion = row['label']\n",
    "                path = os.path.join(self.outputpath, emotion)\n",
    "\n",
    "                if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "\n",
    "                x, sample_rate = librosa.load(row['path'])\n",
    "                self.generate(x, sample_rate, path, index, emotion)\n",
    "\n",
    "    def generate(self, x, sample_rate, path, count, emotion):\n",
    "        if self.mel:\n",
    "            mel_features = librosa.feature.melspectrogram(y=x, sr=sample_rate, n_mels=self.n_mels)\n",
    "            log_mel_features = librosa.power_to_db(mel_features, ref=np.max)\n",
    "            fig = plt.figure(figsize=(12, 4))\n",
    "            ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "            ax.set_axis_off()\n",
    "            fig.add_axes(ax)\n",
    "            librosa.display.specshow(log_mel_features, sr=sample_rate, x_axis='time', y_axis='mel')\n",
    "            if self.sample:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.savefig(os.path.join(path, f'{emotion}_{count}.jpg'))\n",
    "                plt.close()\n",
    "\n",
    "        if self.mfcc:\n",
    "            mfcc_features = librosa.feature.mfcc(x, sr=sample_rate, n_mfcc=self.mfccbanks)\n",
    "            fig = plt.figure(figsize=(12, 4))\n",
    "            ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "            ax.set_axis_off()\n",
    "            fig.add_axes(ax)\n",
    "            librosa.display.specshow(mfcc_features, sr=sample_rate, x_axis='time', y_axis='mel')\n",
    "            if self.sample:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.savefig(os.path.join(path, f'{emotion}_{count}_mfcc.jpg'))\n",
    "                plt.close()\n",
    "\n",
    "        if self.spectral:\n",
    "            spectral_features = librosa.feature.spectral_contrast(x, sr=sample_rate)\n",
    "            fig = plt.figure(figsize=(12, 4))\n",
    "            ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "            ax.set_axis_off()\n",
    "            fig.add_axes(ax)\n",
    "            librosa.display.specshow(spectral_features, sr=sample_rate, x_axis='time', y_axis='mel')\n",
    "            if self.sample:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.savefig(os.path.join(path, f'{emotion}_{count}_spectral.jpg'))\n",
    "                plt.close()\n",
    "\n",
    "        if self.chroma:\n",
    "            chroma_features = librosa.feature.chroma_stft(y=x, sr=sample_rate)\n",
    "            fig = plt.figure(figsize=(12, 4))\n",
    "            ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "            ax.set_axis_off()\n",
    "            fig.add_axes(ax)\n",
    "            librosa.display.specshow(chroma_features, sr=sample_rate, x_axis='time', y_axis='chroma')\n",
    "            if self.sample:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.savefig(os.path.join(path, f'{emotion}_{count}.jpg'))\n",
    "                plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3f0edd",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_images(directory):\n",
    "    total_images = 0\n",
    "    subdirectories = []\n",
    "\n",
    "    # Iterate over all items in the directory\n",
    "    for item in os.listdir(directory):\n",
    "        item_path = os.path.join(directory, item)\n",
    "\n",
    "        # If it's a file and has an image extension, count it\n",
    "        if os.path.isfile(item_path) and item.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "            total_images += 1\n",
    "        # If it's a directory, add it to the subdirectories list\n",
    "        elif os.path.isdir(item_path):\n",
    "            subdirectories.append(item)\n",
    "\n",
    "    # Recursively count images in subdirectories\n",
    "    for subdir in subdirectories:\n",
    "        subdir_path = os.path.join(directory, subdir)\n",
    "        total_images += count_images(subdir_path)\n",
    "\n",
    "    return total_images\n",
    "\n",
    "def count_shape_of_directory(directory):\n",
    "    subdirectories = []\n",
    "    total_images = 0\n",
    "\n",
    "    # Iterate over all items in the directory\n",
    "    for item in os.listdir(directory):\n",
    "        item_path = os.path.join(directory, item)\n",
    "\n",
    "        # If it's a directory, add it to the subdirectories list\n",
    "        if os.path.isdir(item_path):\n",
    "            subdirectories.append(item)\n",
    "        elif os.path.isfile(item_path) and item.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "            total_images += 1\n",
    "    for subdir in subdirectories:\n",
    "        subdir_path = os.path.join(directory, subdir)\n",
    "        total_images += count_images(subdir_path)\n",
    "\n",
    "    return len(subdirectories), total_images\n",
    "directory_path = r\"C:\\Users\\adwit\\Downloads\\new_spectograms\"\n",
    "num_subdirectories, total_images = count_shape_of_directory(directory_path)\n",
    "print(f\"Number of subdirectories: {num_subdirectories}\")\n",
    "print(f\"Total number of images: {total_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d6bb37",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_images(directory):\n",
    "    total_images = 0\n",
    "    subdirectories = []\n",
    "\n",
    "    # Iterate over all items in the directory\n",
    "    for item in os.listdir(directory):\n",
    "        item_path = os.path.join(directory, item)\n",
    "\n",
    "        # If it's a file and has an image extension, count it\n",
    "        if os.path.isfile(item_path) and item.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "            total_images += 1\n",
    "        # If it's a directory, add it to the subdirectories list\n",
    "        elif os.path.isdir(item_path):\n",
    "            subdirectories.append(item)\n",
    "\n",
    "    # Recursively count images in subdirectories\n",
    "    for subdir in subdirectories:\n",
    "        subdir_path = os.path.join(directory, subdir)\n",
    "        total_images += count_images(subdir_path)\n",
    "\n",
    "    return total_images\n",
    "\n",
    "def count_shape_of_directory(directory):\n",
    "    subdirectories = []\n",
    "    total_images = 0\n",
    "\n",
    "    # Iterate over all items in the directory\n",
    "    for item in os.listdir(directory):\n",
    "        item_path = os.path.join(directory, item)\n",
    "\n",
    "        # If it's a directory, add it to the subdirectories list\n",
    "        if os.path.isdir(item_path):\n",
    "            subdirectories.append(item)\n",
    "        elif os.path.isfile(item_path) and item.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "            total_images += 1\n",
    "    for subdir in subdirectories:\n",
    "        subdir_path = os.path.join(directory, subdir)\n",
    "        total_images += count_images(subdir_path)\n",
    "\n",
    "    return len(subdirectories), total_images\n",
    "directory_path = r\"C:\\Users\\adwit\\Downloads\\new_chromagrams\"\n",
    "num_subdirectories, total_images = count_shape_of_directory(directory_path)\n",
    "print(f\"Number of subdirectories: {num_subdirectories}\")\n",
    "print(f\"Total number of images: {total_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2505b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "spectrogram_generator = Spectrograms(df, outputpath=r\"C:\\Users\\adwit\\Downloads\\new_spectograms\", sample=False,mel=True)\n",
    "spectrogram_generator.get_spectrograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667ea128",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "class AugmentedSpectrograms():\n",
    "    def __init__(self, df, outputpath, mel=True, mfcc=False, spectral=False, mfccbanks=20, n_mels=128):\n",
    "        self.df = df\n",
    "        self.mel = mel\n",
    "        self.mfcc = mfcc\n",
    "        self.spectral = spectral\n",
    "        self.mfccbanks = mfccbanks\n",
    "        self.n_mels = n_mels\n",
    "        self.outputpath = outputpath\n",
    "\n",
    "    def get_augmented_spectrograms(self):\n",
    "        for emotion in self.df['label'].unique():\n",
    "            class_df = self.df[self.df['label'] == emotion]\n",
    "            path = os.path.join(self.outputpath, emotion)\n",
    "\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "\n",
    "            print(f\"Processing class {emotion}...\")\n",
    "            count = 0  # Initialize count for each emotion class\n",
    "            for index, row in tqdm(class_df.iterrows(), total=class_df.shape[0]):\n",
    "                x, sample_rate = librosa.load(row['path'])\n",
    "                original_filename = f'{emotion}_{count + 1}'  # Start counting from 1\n",
    "                print(f\"Augmenting {original_filename}...\")\n",
    "                self.generate_augmented_spectrogram(x, sample_rate, path, original_filename)\n",
    "                count += 1  # Increment count after processing each sample\n",
    "\n",
    "    def generate_augmented_spectrogram(self, x, sample_rate, path, original_filename):\n",
    "        if self.mel:\n",
    "            mel_features = librosa.feature.melspectrogram(y=x, sr=sample_rate, n_mels=self.n_mels)\n",
    "            log_mel_features = librosa.power_to_db(mel_features, ref=np.max)\n",
    "\n",
    "            # Apply SpecAugment to the mel spectrogram\n",
    "            augmented_spec = spec_augment(log_mel_features)\n",
    "\n",
    "            # Save the augmented mel spectrogram\n",
    "            self.save_spectrogram(augmented_spec, sample_rate, path, original_filename)\n",
    "\n",
    "    def save_spectrogram(self, features, sample_rate, path, original_filename):\n",
    "        fig = plt.figure(figsize=(12, 4))\n",
    "        ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "        ax.set_axis_off()\n",
    "        fig.add_axes(ax)\n",
    "        librosa.display.specshow(features, sr=sample_rate, x_axis='time', y_axis='mel')\n",
    "\n",
    "        save_path = os.path.join(path, f'{original_filename}.jpg')\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "\n",
    "# Example usage for generating augmented spectrograms\n",
    "outputpath =r\"C:\\Users\\adwit\\Downloads\\new_spectograms\"  # Change this to the desired output path\n",
    "augmented_spectrogram_generator = AugmentedSpectrograms(df, outputpath=outputpath, mel=True, mfcc=False, spectral=False)\n",
    "\n",
    "# Generate augmented spectrograms\n",
    "augmented_spectrogram_generator.get_augmented_spectrograms()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb97ff0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def spec_augment(spec: np.ndarray, num_mask=1,\n",
    "                 freq_masking_max_percentage=0.10, time_masking_max_percentage=0.15):\n",
    "\n",
    "    spec = spec.copy()\n",
    "    for i in range(num_mask):\n",
    "        all_frames_num, all_freqs_num = spec.shape\n",
    "        freq_percentage = random.uniform(0, freq_masking_max_percentage)\n",
    "\n",
    "        num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "        f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "        f0 = int(f0)\n",
    "        spec[:, f0:f0 + num_freqs_to_mask] = 0.000\n",
    "\n",
    "        time_percentage = random.uniform(0.0, time_masking_max_percentage)\n",
    "\n",
    "        num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "        t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "        t0 = int(t0)\n",
    "        spec[t0:t0 + num_frames_to_mask, :] = 0.000\n",
    "\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4b9685",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Main directories containing spectrograms and chromagrams\n",
    "spectrograms_dir = r\"C:\\Users\\adwit\\Downloads\\new_spectograms\"\n",
    "chromagrams_dir =r\"C:\\Users\\adwit\\Downloads\\new_chromagrams\"\n",
    "\n",
    "# Function to count files in subdirectories\n",
    "def count_files_in_subdirectories(directory):\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\"):  # Adjust the file extension as per your file type\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "# Count files in subdirectories\n",
    "num_spectrograms = count_files_in_subdirectories(spectrograms_dir)\n",
    "num_chromagrams = count_files_in_subdirectories(chromagrams_dir)\n",
    "\n",
    "# If there are more spectrogram images than chromagram images\n",
    "if num_spectrograms > num_chromagrams:\n",
    "    # Determine how many spectrogram images need to be deleted\n",
    "    num_to_delete = num_spectrograms - num_chromagrams\n",
    "\n",
    "    # Walk through spectrograms directory and delete excess files\n",
    "    for root, dirs, files in os.walk(spectrograms_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\"):  # Adjust the file extension as per your file type\n",
    "                os.remove(os.path.join(root, file))\n",
    "                num_to_delete -= 1\n",
    "                if num_to_delete == 0:\n",
    "                    break\n",
    "        if num_to_delete == 0:\n",
    "            break\n",
    "\n",
    "    print(f\"{num_to_delete} spectrogram images deleted.\")\n",
    "else:\n",
    "    print(\"No deletion needed. Number of spectrograms matches number of chromagrams.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978527fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Main directories containing spectrograms and chromagrams\n",
    "spectrograms_dir = r\"C:\\Users\\adwit\\Downloads\\new_spectograms\"\n",
    "chromagrams_dir = r\"C:\\Users\\adwit\\Downloads\\new_chromagrams\"\n",
    "\n",
    "# Function to count files in subdirectories\n",
    "def count_files_in_subdirectories(directory):\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\"):  # Adjust the file extension as per your file type\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "# Count files in subdirectories for spectrograms and chromagrams\n",
    "num_spectrograms = count_files_in_subdirectories(spectrograms_dir)\n",
    "num_chromagrams = count_files_in_subdirectories(chromagrams_dir)\n",
    "\n",
    "# If there are more spectrogram images than chromagram images\n",
    "if num_spectrograms > num_chromagrams:\n",
    "    # Determine how many spectrogram images need to be deleted\n",
    "    num_to_delete = num_spectrograms - num_chromagrams\n",
    "\n",
    "    # Walk through spectrograms directory and delete excess files\n",
    "    for root, dirs, files in os.walk(spectrograms_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\"):  # Adjust the file extension as per your file type\n",
    "                os.remove(os.path.join(root, file))\n",
    "                num_to_delete -= 1\n",
    "                if num_to_delete == 0:\n",
    "                    break\n",
    "        if num_to_delete == 0:\n",
    "            break\n",
    "\n",
    "    print(f\"{num_to_delete} spectrogram images deleted.\")\n",
    "else:\n",
    "    print(\"No deletion needed. Number of spectrograms matches number of chromagrams.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19c4439",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    " import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "dataset_dir = r\"C:\\Users\\adwit\\Downloads\\specti-newaug\"\n",
    "\n",
    "spectrograms = []\n",
    "labels = []\n",
    "for emotion_category in os.listdir(dataset_dir):\n",
    "    category_dir = os.path.join(dataset_dir, emotion_category)\n",
    "    if os.path.isdir(category_dir):\n",
    "        for filename in os.listdir(category_dir):\n",
    "            img = load_img(os.path.join(category_dir, filename), target_size=(256,256,3))\n",
    "            img_array = img_to_array(img)\n",
    "            spectrograms.append(img_array)\n",
    "            labels.append(emotion_category)\n",
    "spectrograms = np.array(spectrograms)\n",
    "labels = np.array(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(spectrograms, labels, test_size=0.2, random_state=42)\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train = label_binarizer.fit_transform(y_train)\n",
    "y_test = label_binarizer.transform(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b49c247",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Input, BatchNormalization, Dropout\n",
    "import numpy as np\n",
    "\n",
    "input_shape = (256, 256, 3)\n",
    "\n",
    "# Define the model architecture\n",
    "input_layer1 = Input(shape=input_shape)\n",
    "x1 = Conv2D(32, (3, 3), activation='relu', padding='same', strides=(2, 2))(input_layer1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = MaxPooling2D(pool_size=(3, 3), strides=(3, 3))(x1)\n",
    "\n",
    "input_layer2 = Input(shape=input_shape)\n",
    "x2 = Conv2D(64, (3, 3), activation='relu', padding='same', strides=(2, 2))(input_layer2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = MaxPooling2D(pool_size=(3, 3), strides=(3, 3))(x2)\n",
    "\n",
    "concatenated_input = Concatenate()([x1, x2])\n",
    "\n",
    "x3 = Conv2D(128, (3, 3), activation='relu', padding='same')(concatenated_input)\n",
    "x3 = BatchNormalization()(x3)\n",
    "x3 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x3)\n",
    "# New Convolutional Layer\n",
    "x4 = Conv2D(256, (3,3), activation='relu', padding='same')(x3)\n",
    "x4 = BatchNormalization()(x4)\n",
    "x4 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x4)\n",
    "\n",
    "x5 = Conv2D(512, (3,3), activation='relu', padding='same')(x4)\n",
    "x5 = BatchNormalization()(x5)\n",
    "x5 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x5)\n",
    "\n",
    "flatten_layer = Flatten()(x5)\n",
    "x = Dense(128, activation='elu')(flatten_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Dense(256, activation='elu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Dense(256, activation='elu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Dense(128, activation='elu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "num_classes = 8\n",
    "output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Original model\n",
    "model = Model(inputs=[input_layer1, input_layer2], outputs=output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1255449",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit([X_train, X_train], y_train, batch_size=32, epochs=30, validation_data=([X_test, X_test], y_test))\n",
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming you have trained your CNN model and obtained predictions\n",
    "# Replace these lines with your actual prediction code\n",
    "# model = ... (your CNN model)\n",
    "y_pred = model.predict([X_test, X_test])  # Example of getting predictions, adjust according to your model\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision = precision_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='weighted')\n",
    "recall = recall_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='weighted')\n",
    "f1 = f1_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Average Precision:\", precision)\n",
    "print(\"Average Recall:\", recall)\n",
    "print(\"Average F1-score:\", f1)\n",
    "# Extract accuracy values from history\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract accuracy values from history\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Plot accuracy vs. epochs\n",
    "plt.plot(range(1, len(train_accuracy) + 1), train_accuracy, label='Train')\n",
    "plt.plot(range(1, len(val_accuracy) + 1), val_accuracy, label='Test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. Epochs')              \n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e290db75",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/adwit/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
